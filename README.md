# RAG Assistant

Welcome to **RAG Assistant**, an intelligent assistant powered by **Retrieval-Augmented Generation (RAG)** to provide precise technical answers from PDF documents and web sources. Built with **FastAPI**, **LangChain**, and **Ollama**, this open-source project uses the **Mistral** model (or lighter alternatives like `phi3`) for efficient, multi-language responses (primarily French). It combines vector search (FAISS) and keyword search (BM25) for accurate document retrieval.

## üöÄ Key Features

- **RAG Pipeline**: Combines FAISS vector search and BM25 for accurate, context-aware answers.
- **Data Sources**: Supports PDFs (`app/data/pdfs/`) and web URLs (via `.env`).
- **Multi-Language Support**: Optimized for French, with potential for other languages.
- **Modern API**: FastAPI with Swagger UI for easy interaction.
- **Modular Design**: Extensible for adding new data sources or models.
- **Open-Source**: Uses free, open-source tools (LangChain, Ollama, FAISS).

## üìÇ Project Structure

```
ecommerce-rag-assistant/
‚îú‚îÄ‚îÄ .env                    # Environment variables
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/               # FastAPI endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py        # API entry point
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes/rag.py  # RAG endpoint
‚îÇ   ‚îú‚îÄ‚îÄ chains/            # RAG chain configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_chain.py
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Configuration and logging
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.py
‚îÇ   ‚îú‚îÄ‚îÄ data/              # Data storage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdfs/          # PDF documents
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/         # Data loading and preprocessing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ splitter.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ models/            # LLM configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_factory.py
‚îÇ   ‚îú‚îÄ‚îÄ services/          # RAG pipeline logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_service.py
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore/       # Vector index management
‚îÇ       ‚îî‚îÄ‚îÄ retriever.py
‚îú‚îÄ‚îÄ create_index.py        # Script to build vector index
‚îú‚îÄ‚îÄ requirements.txt       # Dependencies
‚îú‚îÄ‚îÄ tests/                 # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ test_rag.py
‚îî‚îÄ‚îÄ vectorstore/           # FAISS index storage
```

## üõ†Ô∏è Prerequisites

- **Python**: 3.8 or higher
- **Ollama**: For running the LLM locally (Mistral, phi3, or tinyllama)
- **System**:
  - **RAM**: Minimum 8 GB (16 GB recommended for `mistral`; 4-8 GB sufficient for `phi3` or `tinyllama`)
  - **OS**: Windows, Linux (Ubuntu tested), or macOS
  - **CPU**: Multi-core recommended
  - **GPU**: Optional (NVIDIA with CUDA for better performance)
- **Disk Space**: ~1 GB for models and vector index
- **Dependencies**: Listed in `requirements.txt`

## üì¶ Installation

1. **Clone the repository**:

   ```bash
   git clone https://github.com/adamaKomi/rag.git
   cd rag
   ```

2. **Create a virtual environment**:

   - **Windows**:
     ```bash
     python -m venv venv
     venv\Scripts\activate
     ```
   - **Linux/macOS**:
     ```bash
     python -m venv venv
     source venv/bin/activate
     ```

3. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

4. **Install Ollama**:
   - Download and install Ollama from [ollama.com](https://ollama.com/download).
   - Pull a lightweight model (recommended for low-memory systems):
     ```bash
     ollama pull phi3
     ```
     Or use `mistral` if you have sufficient RAM (>16 GB):
     ```bash
     ollama pull mistral
     ```

5. **Set up environment variables**:
   - Create a `.env` file at the project root:
     ```
     PDF_DIR=app/data/pdfs/
     VECTORSTORE_DIR=vectorstore/
     USER_AGENT=MyApp/1.0
     WEB_SOURCES=https://example.com,https://another-example.com  # Optional
     ```

6. **Prepare PDF documents**:
   - Create the directory `app/data/pdfs/` if it doesn‚Äôt exist:
     ```bash
     mkdir -p app/data/pdfs
     ```
   - Place PDF files in `app/data/pdfs/`.

7. **Create the vector index**:

   ```bash
   python create_index.py
   ```

8. **Start the Ollama server**:
   - In a separate terminal:
     ```bash
     ollama serve
     ```

9. **Launch the API**:

   ```bash
   uvicorn app.api.main:app --host 0.0.0.0 --port 8000
   ```

## üöÄ Usage

### Via the API

Send a POST request to the `/rag` endpoint:

```bash
curl -X POST http://localhost:8000/rag -H "Content-Type: application/json" -d '{"query": "Quelle est la capitale de la France ?"}'
```

Expected response:

```json
{
  "result": "La capitale de la France est Paris.",
  "sources": [],
  "status": "success"
}
```

Access the Swagger UI at `http://localhost:8000/docs` for interactive testing.

### Via Browser

Visit `http://localhost:8000/docs` to test the API using the Swagger interface.

## üß™ Tests

Run unit tests:

```bash
pytest tests/test_rag.py
```

## ‚ö†Ô∏è Troubleshooting

- **Memory Error with Mistral**:
  - Error: `model requires more system memory (5.5 GiB) than is available (3.6 GiB)`.
  - Solution: Use a lighter model like `phi3` or `tinyllama`. Update `app/chains/rag_chain.py` and `app/models/llm_factory.py`:
    ```python
    llm = OllamaLLM(model="phi3", ...)
    ```
    Then pull the model:
    ```bash
    ollama pull phi3
    ```
  - Alternatively, increase RAM or swap space:
    - **Windows**: Adjust virtual memory in System Properties ‚Üí Advanced ‚Üí Performance ‚Üí Virtual Memory.
    - **Linux**: Increase swap with `sudo fallocate -l 8G /swapfile` and related commands.

- **Ollama Server Not Running**:
  - Ensure `ollama serve` is running before starting the API.

- **No PDFs Found**:
  - Verify that `app/data/pdfs/` contains valid PDF files. Create the directory if missing:
    ```bash
    mkdir -p app/data/pdfs
    ```

- **GPU Not Detected**:
  - If no NVIDIA GPU is available, the system defaults to CPU. Ensure CUDA drivers are installed if using a compatible GPU.

## üìû Contact

For questions or issues, contact the maintainers:

- Azzedine ZEMMARI (azzedinezemmari@gmail.com)
- Adama KOMI (adamakomi15@gmail.com)

Or open an issue on [GitHub](https://github.com/adamaKomi/rag).

---

‚≠ê **Star this project on GitHub if you find it useful!**